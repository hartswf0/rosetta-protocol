<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Operative Ekphrasis and Generative AI</title>
    <style>
        /* --- Reset and Base Styles --- */
        :root {
            --bg-color: #1a1a1a;
            --text-color: #e0e0e0;
            --primary-color: #00aaff;
            --primary-accent: #0077b3;
            --note-bg: #2a2a2a;
            --note-text: #b0b0b0;
            --border-color: #444;
            --sans-font: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif, "Apple Color Emoji", "Segoe UI Emoji", "Segoe UI Symbol";
            --serif-font: "Iowan Old Style", "Apple Garamond", Baskerville, "Times New Roman", "Droid Serif", Times, "Source Serif Pro", serif, "Apple Color Emoji", "Segoe UI Emoji", "Segoe UI Symbol";
        }

        * {
            box-sizing: border-box;
            margin: 0;
            padding: 0;
        }

        html, body {
            width: 100%;
            height: 100%;
            overflow: hidden;
            background-color: var(--bg-color);
            color: var(--text-color);
            font-family: var(--sans-font);
            font-size: 16px;
            line-height: 1.6;
        }

        /* --- Presentation Container --- */
        main {
            width: 100%;
            height: 100%;
            position: relative;
        }

        /* --- Slide Styles --- */
        .slide {
            width: 100%;
            height: 100%;
            position: absolute;
            top: 0;
            left: 0;
            display: flex;
            flex-direction: column;
            justify-content: center;
            align-items: center;
            padding: 5vmin;
            opacity: 0;
            visibility: hidden;
            transition: opacity 0.5s ease-in-out, visibility 0.5s ease-in-out;
            transform: translateX(20px);
        }

        .slide.active {
            opacity: 1;
            visibility: visible;
            transform: translateX(0);
            z-index: 1;
        }

        .slide-content {
            width: 100%;
            max-width: 900px;
            text-align: center;
        }
        
        /* --- Typography --- */
        h1, h2, h3 {
            font-family: var(--serif-font);
            font-weight: 600;
            line-height: 1.2;
            margin-bottom: 0.75em;
            color: var(--text-color);
        }

        h1 { font-size: clamp(2.5rem, 8vmin, 4.5rem); }
        h2 { font-size: clamp(2rem, 6vmin, 3.5rem); }
        h3 { font-size: clamp(1.5rem, 4vmin, 2.5rem); }

        p {
            font-size: clamp(1rem, 2.5vmin, 1.25rem);
            margin-bottom: 1em;
        }

        strong { color: var(--primary-color); }

        blockquote {
            font-family: var(--serif-font);
            font-style: italic;
            border-left: 3px solid var(--primary-color);
            padding-left: 1.5em;
            margin: 2em 0;
            font-size: clamp(1.1rem, 3vmin, 1.5rem);
        }

        /* --- Layout Helpers --- */
        .two-columns {
            display: flex;
            flex-direction: column;
            gap: 2rem;
            text-align: left;
            margin-top: 2rem;
        }

        @media (min-width: 768px) {
            .two-columns {
                flex-direction: row;
            }
        }
        
        .two-columns > div {
            flex: 1;
            border: 1px solid var(--border-color);
            padding: 1.5rem;
            border-radius: 8px;
            background-color: rgba(255,255,255,0.03);
        }

        /* --- Speaker Notes --- */
        .speaker-notes {
            display: none; /* Hidden by default, toggled by JS */
            position: fixed;
            bottom: 0;
            left: 0;
            width: 100%;
            max-height: 40vh;
            overflow-y: auto;
            background-color: var(--note-bg);
            color: var(--note-text);
            padding: 2em;
            border-top: 2px solid var(--border-color);
            z-index: 100;
            font-size: 0.9rem;
            line-height: 1.5;
        }

        .speaker-notes h4 {
            font-family: var(--sans-font);
            text-transform: uppercase;
            letter-spacing: 1px;
            color: var(--primary-color);
            margin-bottom: 1em;
            border-bottom: 1px solid var(--border-color);
            padding-bottom: 0.5em;
        }
        
        .speaker-notes p { font-size: 0.9rem; }
        .speaker-notes ul { list-style-position: inside; padding-left: 1em;}

        /* --- UI Controls --- */
        .controls, .slide-counter, .notes-toggle {
            position: fixed;
            z-index: 10;
            -webkit-user-select: none; user-select: none;
        }
        
        .controls {
            bottom: 2vmin;
            right: 2vmin;
            display: flex;
            gap: 0.5rem;
        }

        .controls button {
            background-color: rgba(255, 255, 255, 0.1);
            border: 1px solid var(--border-color);
            color: var(--text-color);
            font-size: 1.5rem;
            width: 50px;
            height: 50px;
            border-radius: 50%;
            cursor: pointer;
            transition: background-color 0.2s, transform 0.2s;
        }
        
        .controls button:hover {
            background-color: var(--primary-accent);
        }

        .slide-counter {
            bottom: 3.5vmin;
            left: 3.5vmin;
            font-size: 1rem;
            background-color: rgba(0,0,0,0.3);
            padding: 0.5em 1em;
            border-radius: 20px;
        }
        
        .notes-toggle {
            top: 2vmin;
            right: 2vmin;
            background-color: transparent;
            border: none;
            color: #888;
            font-size: 0.8rem;
            cursor: pointer;
            padding: 0.5em;
        }
        .notes-toggle:hover { color: var(--text-color); }
        
        /* --- Special Slide Content --- */
        #slide-title .subtitle {
            font-size: clamp(1rem, 3vmin, 1.5rem);
            color: var(--note-text);
            margin-top: 1rem;
        }
        
        #diagram {
            font-family: monospace;
            font-size: clamp(0.9rem, 2.5vmin, 1.2rem);
            background-color: var(--note-bg);
            padding: 2em;
            border-radius: 10px;
            border: 1px solid var(--border-color);
            display: inline-block;
            margin-top: 1rem;
        }

        ul.criteria-list {
            display: inline-block;
            text-align: left;
            list-style: none;
            margin-top: 1rem;
        }
        ul.criteria-list li {
            background: rgba(255,255,255,0.05);
            padding: 0.5em 1em;
            margin-bottom: 0.5em;
            border-radius: 5px;
            transition: background-color 0.2s;
        }
        ul.criteria-list li:hover { background-color: var(--primary-accent); }
    </style>
</head>
<body>

    <main id="presentation">
        <!-- SLIDE 1: Title -->
        <section class="slide" id="slide-1">
            <div class="slide-content" id="slide-title">
                <h1>Operative Ekphrasis<br>& Generative AI</h1>
                <p class="subtitle">A New Mode of Creative Production</p>
            </div>
            <div class="speaker-notes">
                <h4>SPEAKER NOTES</h4>
                <p>Welcome. Today we're exploring a new framework for understanding the creative output of Generative AI systems like DALL-E, Midjourney, and GPT.</p>
                <p>The source text argues that these tools have produced a "lush jungle of content" that challenges our core assumptions about media, creativity, and authorship. To navigate this jungle, we need a new concept: <strong>Operative Ekphrasis</strong>.</p>
            </div>
        </section>

        <!-- SLIDE 2: The Collapse -->
        <section class="slide" id="slide-2">
            <div class="slide-content">
                <h2>The Collapse</h2>
                <p><strong>Operative Ekphrasis</strong> is when the traditional act of describing an image in words is <strong>reversed or collapsed.</strong></p>
                <h3>Text ⇄ Image</h3>
                <p>This reflects a fundamental "collapse of the text/image distinction" under multimodal AI. The boundary becomes a loop.</p>
            </div>
            <div class="speaker-notes">
                <h4>SPEAKER NOTES</h4>
                <p>Let's define our core term. Classical ekphrasis is the verbal description of visual art. Think of a poem about a painting.</p>
                <p><strong>Operative Ekphrasis</strong> is different. It's not about description; it's about <em>generation</em>. Text directly produces an image. An image can be "read" by a vision model to produce a text. The line between them dissolves.</p>
                <p>As the source text says, "Ekphrasis is both effectuated and defied by machinery." The machine doesn't just describe, it *does*. It performs the link between modalities.</p>
            </div>
        </section>

        <!-- SLIDE 3: Classical vs. Operative -->
        <section class="slide" id="slide-3">
            <div class="slide-content">
                <h2>From Battle to Loop</h2>
                <div class="two-columns">
                    <div>
                        <h3>Classical Ekphrasis (A Battle)</h3>
                        <p>The verbal representation of visual art. A "tension between verbal and visual modes" where language tries to capture a silent image. (Heffernan, Krieger)</p>
                    </div>
                    <div>
                        <h3>Operative Ekphrasis (A Loop)</h3>
                        <p>A performative, transmedial act. Text and image co-emerge in a machine process. It "transcends the difference" between them. (Bajohr)</p>
                    </div>
                </div>
            </div>
            <div class="speaker-notes">
                <h4>SPEAKER NOTES</h4>
                <p>This slide highlights the historical shift. For centuries, ekphrasis was seen as a "battle for mastery between the image and the word." The canonical example is Homer's detailed description of the Shield of Achilles. It was a struggle.</p>
                <p>Generative AI changes the dynamic entirely. It's no longer a battle, but a cooperative, generative loop. Hannes Bajohr, who coined the term "operative ekphrasis," argues it's a performative act. The AI isn't just representing something that already exists; it's performing the creation of something new by bridging these two modes algorithmically.</p>
            </div>
        </section>

        <!-- SLIDE 4: Plenitude vs Scarcity -->
        <section class="slide" id="slide-4">
            <div class="slide-content">
                <h2>Plenitude vs. Scarcity</h2>
                <p>This new era is defined by <strong>plenitude</strong>—an overwhelming abundance of content.</p>
                <p>This challenges traditional value, which was based on <strong>scarcity</strong> and Walter Benjamin's concept of <strong>"aura"</strong>.</p>
                <blockquote>"What value can a unique image hold if anybody can use their phone to make a similar unique image in just a few seconds?"</blockquote>
            </div>
            <div class="speaker-notes">
                <h4>SPEAKER NOTES</h4>
                <p>Here we get to the aesthetic and economic consequences. Walter Benjamin argued that a work of art's "aura" comes from its unique presence in time and space. Mechanical reproduction, like photography, already threatened this aura.</p>
                <p>Generative AI creates what the text calls a "generative jungle" of infinite, unique-but-not-scarce images. This leads to phenomena like "AI Slop"—low-quality, banal, and pointless content flooding our feeds.</p>
                <p>The quote on the slide captures the core problem. If uniqueness is easy to achieve, it ceases to be a primary source of value. The new scarce resource is no longer the unique object, but rather human attention, curation, and context.</p>
            </div>
        </section>
        
        <!-- SLIDE 5: New Roles -->
        <section class="slide" id="slide-5">
            <div class="slide-content">
                <h2>Who Creates? Who Consumes?</h2>
                 <div class="two-columns">
                    <div>
                        <h3>Making → Cyborg Authorship</h3>
                        <p>Authorship blurs from a single creator to a network. It becomes a <strong>cooperative interaction between human and machine</strong>.</p>
                    </div>
                    <div>
                        <h3>Consuming → A Networked Audience</h3>
                        <p>The audience is not just us. It includes casual scrollers, expert curators, platform algorithms, and even <strong>other AIs in feedback loops</strong>.</p>
                    </div>
                </div>
            </div>
            <div class="speaker-notes">
                <h4>SPEAKER NOTES</h4>
                <p>The roles of creator and consumer are fundamentally changing. Is the author the person writing the prompt, the developer who trained the model, or the AI itself? The text suggests we think of it as "distributed" or "cyborg" authorship—a hybrid, collaborative process.</p>
                <p>On the other side, the audience is also more complex. We are viewers, but so are the algorithms that decide what content gets promoted. Crucially, AI systems are often trained on content generated by other AIs, creating strange, recursive feedback loops. We are all part of a vast, interconnected network of production and consumption.</p>
            </div>
        </section>

        <!-- SLIDE 6: New Criteria -->
        <section class="slide" id="slide-6">
            <div class="slide-content">
                <h2>New Criteria for a New Art</h2>
                <p>In an age of plenitude, "does it look good?" is not enough. We need new frameworks for evaluation.</p>
                <ul class="criteria-list">
                    <li><strong>Novelty:</strong> Is it original or derivative?</li>
                    <li><strong>Coherence:</strong> Is it internally consistent?</li>
                    <li><strong>Style:</strong> Does it exhibit a distinctive aesthetic?</li>
                    <li><strong>Intention:</strong> How well does it meet its goal?</li>
                    <li><strong>Impact:</strong> What is its effect on culture?</li>
                    <li><strong>Traceability:</strong> Can we trace its sources? (An ethical question)</li>
                    <li><strong>Control:</strong> How much human agency was involved?</li>
                </ul>
            </div>
            <div class="speaker-notes">
                <h4>SPEAKER NOTES</h4>
                <p>If uniqueness and traditional craft are no longer reliable markers of value, how do we judge this new work? The paper proposes a multi-dimensional approach.</p>
                <p>We need to ask different questions. Instead of just assessing the final object, we must consider the process. Was it novel? Did the artist (or artist-machine team) have clear intention? Is the process transparent and traceable? This last point is crucial for ethical considerations, especially regarding training data.</p>
                <p>These criteria shift the focus from the artifact alone to the entire system of its creation and reception.</p>
            </div>
        </section>
        
        <!-- SLIDE 7: Recursive Loop -->
        <section class="slide" id="slide-7">
            <div class="slide-content">
                <h2>The Recursive Loop in Action</h2>
                <p>Operative ekphrasis enables purely machine-driven creative cycles.</p>
                <div id="diagram">
                    Text₁ (Prompt) → Image₁ (AI) <br>
                    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;↓ <br>
                    Image₁ → Text₂ (Vision AI) <br>
                    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;↓ <br>
                    Text₂ → Image₂ (AI) <br>
                    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;↓ <br>
                    ... and so on ...
                </div>
                <p>This can lead to "telephone game" style distortion or crystallize entirely new concepts.</p>
            </div>
            <div class="speaker-notes">
                <h4>SPEAKER NOTES</h4>
                <p>This is one of the most powerful and tangible examples from the text. Imagine you start with a poetic line. You generate an image from it. Then, you use a different AI to describe that new image in words. You take that new description and feed it back into the image generator. You repeat the process.</p>
                <p>What happens? The system is talking to itself. It's a closed loop. The original meaning might drift and degrade, like in the game of telephone. Or, it might unexpectedly converge on a new, stable, and fascinating visual idea.</p>
                <p>This experiment dramatically illustrates the collapse of the text/image boundary and the unpredictable nature of these generative systems.</p>
            </div>
        </section>
        
        <!-- SLIDE 8: Conclusion -->
        <section class="slide" id="slide-8">
            <div class="slide-content">
                <h2>Rupture & Continuity</h2>
                 <div class="two-columns">
                    <div>
                        <h3>Continuity</h3>
                        <p>Operative ekphrasis continues the ancient human attraction to merging word and image.</p>
                    </div>
                    <div>
                        <h3>Rupture</h3>
                        <p>It radically changes the conditions: from scarcity to <strong>plenitude</strong>, from authorship to <strong>operation</strong>, from contemplation to <strong>consumption</strong>.</p>
                    </div>
                </div>
            </div>
            <div class="speaker-notes">
                <h4>SPEAKER NOTES</h4>
                <p>So, what does this all mean? The paper argues for a perspective of both continuity and rupture.</p>
                <p>On one hand, this is nothing new. We've always been fascinated by making words create pictures in our minds. In a way, AI is simply fulfilling the "ancient promise of poetry to 'make us see'," but through computation instead of rhetoric.</p>
                <p>On the other hand, the break with the past is profound. The economic and cultural logic is completely different. The shift from a world based on scarce originals to one of infinite generation is a fundamental rupture that we are still trying to understand.</p>
            </div>
        </section>

        <!-- SLIDE 9: Final Thought -->
        <section class="slide" id="slide-9">
            <div class="slide-content">
                <h2>Welcome to the Jungle</h2>
                <blockquote>"We now face a jungle that is at once fertile and impenetrable: a jungle of ideas that can confuse as much as inspire."</blockquote>
                <p>Our path forward depends on who we imagine ourselves to be: weary explorers, curious botanists, or the new hybrid creatures we create.</p>
            </div>
            <div class="speaker-notes">
                <h4>SPEAKER NOTES</h4>
                <p>To conclude, the text leaves us with this powerful metaphor of the jungle. It perfectly captures the current moment: it's a space of incredible creative fertility, but it's also dense, chaotic, and easy to get lost in.</p>
                <p>There's no clear map. The final question is about our role within this new ecosystem. Do we try to tame it? Do we simply study it? Or do we become part of it, collaborating with these new tools to become something new ourselves?</p>
                <p>Thank you.</p>
            </div>
        </section>

    </main>

    <!-- UI Elements -->
    <div class="slide-counter" id="slide-counter">1 / 9</div>
    <div class="controls">
        <button id="prev-btn">‹</button>
        <button id="next-btn">›</button>
    </div>
    <div class="notes-toggle" id="notes-toggle-btn">Press 'N' for Notes</div>

    <script>
        document.addEventListener('DOMContentLoaded', () => {
            const slides = document.querySelectorAll('.slide');
            const prevBtn = document.getElementById('prev-btn');
            const nextBtn = document.getElementById('next-btn');
            const notesToggleBtn = document.getElementById('notes-toggle-btn');
            const slideCounter = document.getElementById('slide-counter');

            let currentSlide = 0;
            const totalSlides = slides.length;

            const updatePresentation = () => {
                // Update slides
                slides.forEach((slide, index) => {
                    if (index === currentSlide) {
                        slide.classList.add('active');
                        // Update speaker notes
                        const currentNotes = slide.querySelector('.speaker-notes');
                        document.querySelectorAll('.speaker-notes').forEach(note => note.style.display = 'none');
                        if (currentNotes && notesVisible) {
                            currentNotes.style.display = 'block';
                        }
                    } else {
                        slide.classList.remove('active');
                    }
                });

                // Update counter
                slideCounter.textContent = `${currentSlide + 1} / ${totalSlides}`;

                // Update URL hash
                window.location.hash = `slide-${currentSlide + 1}`;
            };

            const goToSlide = (slideNumber) => {
                currentSlide = slideNumber;
                updatePresentation();
            };

            const goToNext = () => {
                currentSlide = (currentSlide + 1) % totalSlides;
                updatePresentation();
            };

            const goToPrev = () => {
                currentSlide = (currentSlide - 1 + totalSlides) % totalSlides;
                updatePresentation();
            };

            // Speaker Notes Logic
            let notesVisible = false;
            const toggleNotes = () => {
                notesVisible = !notesVisible;
                notesToggleBtn.textContent = notesVisible ? "Press 'N' to Hide Notes" : "Press 'N' for Notes";
                updatePresentation(); // Re-run to show/hide notes for the active slide
            };

            // Event Listeners
            nextBtn.addEventListener('click', goToNext);
            prevBtn.addEventListener('click', goToPrev);
            notesToggleBtn.addEventListener('click', toggleNotes);

            document.addEventListener('keydown', (e) => {
                if (e.key === 'ArrowRight' || e.key === ' ') {
                    goToNext();
                } else if (e.key === 'ArrowLeft') {
                    goToPrev();
                } else if (e.key.toLowerCase() === 'n') {
                    toggleNotes();
                }
            });

            // Initial setup on page load
            const initialSlide = parseInt(window.location.hash.replace('#slide-', ''), 10) - 1;
            if (!isNaN(initialSlide) && initialSlide >= 0 && initialSlide < totalSlides) {
                currentSlide = initialSlide;
            }
            updatePresentation();
        });
    </script>
</body>
</html>